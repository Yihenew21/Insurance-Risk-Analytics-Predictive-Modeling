{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 3: Comprehensive Hypothesis Testing Notebook\n",
        "\n",
        "## Overview\n",
        "This notebook analyzes historical insurance data (Feb 2014 - Aug 2015) for AlphaCare Insurance Solutions (ACIS) to test 28 null hypotheses on risk drivers. Risk metrics include Claim Frequency, Claim Severity, and Margin. Analysis and visualizations are performed here using imported functions.\n",
        "\n",
        "## Objectives\n",
        "- Load and preprocess data.\n",
        "- Calculate overall metrics.\n",
        "- Test hypotheses across 28 variables.\n",
        "- Generate and interpret visualizations.\n",
        "- Provide business recommendations.\n",
        "\n",
        "## Prerequisites\n",
        "- Install dependencies from requirements.txt.\n",
        "- Ensure data/raw/insurance_data.txt exists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "src_path added to sys.path: c:\\Users\\hp\\Desktop\\projects\\10 Acadamy -KAIM5\\Insurance-Risk-Analytics-Predictive-Modeling\\src\n",
            "stats exists: True\n",
            "hypothesis_testing.py exists: True\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Import Libraries\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats  # Added for statistical tests\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd  # Added for Tukey HSD test\n",
        "\n",
        "# Add src to Python path (project root aware)\n",
        "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "src_path = os.path.join(project_root, \"src\")\n",
        "if src_path not in sys.path:\n",
        "    sys.path.insert(0, src_path)\n",
        "print(\"src_path added to sys.path:\", src_path)\n",
        "print(\"stats exists:\", os.path.exists(os.path.join(src_path, \"stats\")))\n",
        "print(\"hypothesis_testing.py exists:\", os.path.exists(os.path.join(src_path, \"stats\", \"hypothesis_testing.py\")))\n",
        "\n",
        "from stats.hypothesis_testing import calculate_metrics, segment_data, test_hypothesis, visualize_results\n",
        "\n",
        "# Set plotting style for better visuals\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Documentation\n",
        "# - sys/os: Used to add src to Python path dynamically, resolving ModuleNotFoundError in VS Code.\n",
        "# - pandas: For data manipulation and analysis.\n",
        "# - matplotlib/seaborn: For data visualization.\n",
        "# - scipy.stats: Provides statistical functions (e.g., t-test, ANOVA) used in hypothesis testing.\n",
        "# - statsmodels.stats.multicomp: Provides pairwise_tukeyhsd for post-hoc analysis.\n",
        "# - stats.hypothesis_testing: Custom module with testing functions, imported relative to src.\n",
        "# - plt.style.use/seaborn.set_palette: Enhances plot aesthetics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\2982703745.py:4: DtypeWarning: Columns (0,32,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(data_path, sep=\"|\", parse_dates=[\"TransactionMonth\"])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Shape: (845326, 55)\n",
            "Columns: ['UnderwrittenCoverID', 'PolicyID', 'TransactionMonth', 'IsVATRegistered', 'Citizenship', 'LegalType', 'Title', 'Language', 'Bank', 'AccountType', 'MaritalStatus', 'Gender', 'Country', 'Province', 'PostalCode', 'MainCrestaZone', 'SubCrestaZone', 'ItemType', 'mmcode', 'VehicleType', 'RegistrationYear', 'make', 'Model', 'Cylinders', 'cubiccapacity', 'kilowatts', 'bodytype', 'NumberOfDoors', 'VehicleIntroDate', 'CustomValueEstimate', 'AlarmImmobiliser', 'TrackingDevice', 'CapitalOutstanding', 'NewVehicle', 'WrittenOff', 'Rebuilt', 'Converted', 'CrossBorder', 'NumberOfVehiclesInFleet', 'SumInsured', 'TermFrequency', 'CalculatedPremiumPerTerm', 'ExcessSelected', 'CoverCategory', 'CoverType', 'CoverGroup', 'Section', 'Product', 'StatutoryClass', 'StatutoryRiskType', 'TotalPremium', 'TotalClaims', 'TotalPremiumBin', 'SumInsuredBin', 'RegistrationYearBin']\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Load and Preprocess Data\n",
        "# Load the insurance dataset with pipe delimiter and parse dates\n",
        "data_path = os.path.join(project_root, \"data\", \"raw\", \"insurance_data.txt\")\n",
        "df = pd.read_csv(data_path, sep=\"|\", parse_dates=[\"TransactionMonth\"])\n",
        "\n",
        "# Drop rows with missing values for key columns (only those that exist)\n",
        "columns_to_check = [\"TotalClaims\", \"TotalPremium\", \"Province\", \"PostalCode\", \"Gender\", \"UnderwrittenCoverID\", \"PolicyID\",\n",
        "                    \"IsVATRegistered\", \"Citizenship\", \"LegalType\", \"MaritalStatus\", \"Language\", \"Bank\", \"Country\",\n",
        "                    \"MainCrestaZone\", \"SubCrestaZone\", \"ItemType\", \"VehicleType\", \"AlarmImmobiliser\", \"make\",\n",
        "                    \"bodytype\", \"RegistrationYear\", \"TermFrequency\", \"CoverCategory\", \"Product\", \"StatutoryClass\",\n",
        "                    \"SumInsured\"]\n",
        "existing_columns = [col for col in columns_to_check if col in df.columns]\n",
        "missing_columns = [col for col in columns_to_check if col not in df.columns]\n",
        "if missing_columns:\n",
        "    print(\"Warning: The following columns are missing from the data and will be ignored:\", missing_columns)\n",
        "df = df.dropna(subset=existing_columns)\n",
        "\n",
        "# Bin continuous variables for categorical testing\n",
        "df[\"TotalPremiumBin\"] = pd.qcut(df[\"TotalPremium\"], 4, labels=[\"Low\", \"Medium-Low\", \"Medium-High\", \"High\"])\n",
        "df[\"SumInsuredBin\"] = pd.qcut(df[\"SumInsured\"], 4, labels=[\"Low\", \"Medium-Low\", \"Medium-High\", \"High\"])\n",
        "df[\"RegistrationYearBin\"] = pd.cut(df[\"RegistrationYear\"], bins=5, labels=[\"Very Old\", \"Old\", \"Average\", \"New\", \"Very New\"])\n",
        "\n",
        "# Display basic info to verify data loading\n",
        "print(\"Data Shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall Metrics:\n",
            "Claim Frequency 0.0030\n",
            "Claim Severity 22895.4291\n",
            "Margin -7455504.7379\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Calculate Overall Metrics\n",
        "# Compute baseline metrics for the entire dataset\n",
        "metrics = calculate_metrics(df)\n",
        "\n",
        "# Display results\n",
        "print(\"Overall Metrics:\")\n",
        "for metric, value in metrics.items():\n",
        "    print(\"{0} {1:.4f}\".format(metric.replace(\"_\", \" \").title(), value))\n",
        "\n",
        "# Documentation\n",
        "# - calculate_metrics: Computes Claim Frequency, Severity, and Margin.\n",
        "# - print: Formats and displays metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Insufficient unique values for Language in Claim Frequency by Language, skipping.\n",
            "Warning: Insufficient unique values for Country in Claim Frequency by Country, skipping.\n",
            "Warning: Insufficient unique values for ItemType in Claim Frequency by Item Type, skipping.\n",
            "Warning: Insufficient unique values for StatutoryClass in Margin by Statutory Class, skipping.\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Define Hypotheses with A/B Splits\n",
        "# Define hypotheses with specific A/B groups for segmentation\n",
        "hypotheses = []\n",
        "base_hypotheses = [\n",
        "    ([\"Province\"], [\"Gauteng\", \"Western Cape\"], \"TotalClaims\", False, \"Claim Severity by Province\", \"box\"),  # Top 2 provinces by population\n",
        "    ([\"PostalCode\"], df[\"PostalCode\"].value_counts().head(2).index.tolist(), \"TotalClaims\", False, \"Claim Severity by Zip Code\", \"box\"),  # Dynamic top 2 postal codes\n",
        "    ([\"Gender\"], [\"Male\", \"Female\"], \"TotalClaims\", True, \"Claim Frequency by Gender\", \"box\"),  # Binary feature\n",
        "    ([\"PostalCode\"], df[\"PostalCode\"].value_counts().head(2).index.tolist(), pd.Series(df[\"TotalPremium\"] - df[\"TotalClaims\"]), False, \"Margin by Zip Code\", \"box\"),  # Dynamic top 2 postal codes\n",
        "    ([\"UnderwrittenCoverID\"], [], \"TotalClaims\", True, \"Claim Frequency by Cover ID\", \"box\"),  # Dynamic top 2 cover IDs\n",
        "    ([\"PolicyID\"], [], \"TotalClaims\", False, \"Claim Severity by Policy ID\", \"box\"),  # Dynamic top 2 policy IDs\n",
        "    ([\"IsVATRegistered\"], [0, 1], \"TotalClaims\", True, \"Claim Frequency by VAT Status\", \"box\"),  # Binary feature\n",
        "    ([\"Citizenship\"], [], \"TotalClaims\", True, \"Claim Severity by Citizenship\", \"box\"),  # Dynamic top 2 citizenships\n",
        "    ([\"LegalType\"], [], \"TotalClaims\", True, \"Claim Frequency by Legal Type\", \"box\"),  # Dynamic top 2 legal types\n",
        "    ([\"MaritalStatus\"], [], pd.Series(df[\"TotalPremium\"] - df[\"TotalClaims\"]), False, \"Margin by Marital Status\", \"box\"),  # Dynamic top 2 marital statuses\n",
        "    ([\"Language\"], [], \"TotalClaims\", True, \"Claim Frequency by Language\", \"box\"),  # Dynamic top 2 languages\n",
        "    ([\"Bank\"], [], \"TotalClaims\", False, \"Claim Severity by Bank\", \"box\"),  # Dynamic top 2 banks\n",
        "    ([\"Country\"], [], \"TotalClaims\", True, \"Claim Frequency by Country\", \"box\"),  # Dynamic top 2 countries\n",
        "    ([\"MainCrestaZone\"], [], \"TotalClaims\", False, \"Claim Severity by Main Cresta Zone\", \"box\"),  # Dynamic top 2 main zones\n",
        "    ([\"SubCrestaZone\"], [], \"TotalClaims\", True, \"Claim Frequency by Sub Cresta Zone\", \"box\"),  # Dynamic top 2 sub-zones\n",
        "    ([\"ItemType\"], [], \"TotalClaims\", True, \"Claim Frequency by Item Type\", \"box\"),  # Dynamic top 2 item types\n",
        "    ([\"VehicleType\"], [], \"TotalClaims\", False, \"Claim Severity by Vehicle Type\", \"box\"),  # Dynamic top 2 vehicle types\n",
        "    ([\"AlarmImmobiliser\"], [0, 1], \"TotalClaims\", True, \"Claim Frequency by Alarm\", \"box\"),  # Binary feature\n",
        "    ([\"make\"], [], \"TotalClaims\", False, \"Claim Severity by Make\", \"box\"),  # Dynamic top 2 makes\n",
        "    ([\"bodytype\"], [], \"TotalClaims\", True, \"Claim Frequency by Body Type\", \"box\"),  # Dynamic top 2 body types\n",
        "    ([\"RegistrationYear\"], [], pd.Series(df[\"TotalPremium\"] - df[\"TotalClaims\"]), False, \"Margin by Registration Year\", \"box\"),  # Dynamic top 2 years\n",
        "    ([\"TermFrequency\"], [0, 1], \"TotalClaims\", True, \"Claim Frequency by Term Frequency\", \"box\"),  # Binary feature (corrected to explicit 0, 1)\n",
        "    ([\"CoverCategory\"], [], \"TotalClaims\", False, \"Claim Severity by Cover Category\", \"box\"),  # Dynamic top 2 categories\n",
        "    ([\"Product\"], [], \"TotalClaims\", True, \"Claim Frequency by Product\", \"box\"),  # Dynamic top 2 products\n",
        "    ([\"StatutoryClass\"], [], pd.Series(df[\"TotalPremium\"] - df[\"TotalClaims\"]), False, \"Margin by Statutory Class\", \"box\"),  # Dynamic top 2 classes\n",
        "    ([\"TotalPremiumBin\"], [], \"TotalClaims\", True, \"Claim Frequency by Premium Level\", \"box\"),  # Dynamic top 2 bins\n",
        "    ([\"SumInsuredBin\"], [], \"TotalClaims\", False, \"Claim Severity by Sum Insured\", \"box\"),  # Dynamic top 2 bins\n",
        "    ([\"TransactionMonth\"], [], \"TotalClaims\", False, \"Claim Severity by Month\", \"heatmap\"),  # Dynamic top 2 months\n",
        "]\n",
        "\n",
        "for group_col, groups, metric_col, is_cat, title, plot_type in base_hypotheses:\n",
        "    try:\n",
        "        if len(groups) == 2 and isinstance(groups[0], str):  # Predefined A/B pairs\n",
        "            hypotheses.append((group_col, groups, metric_col, is_cat, title, plot_type))\n",
        "        else:  # Dynamic A/B pairs\n",
        "            top_two = df[group_col[0]].value_counts().head(2).index.tolist()\n",
        "            if len(top_two) == 2:\n",
        "                hypotheses.append((group_col, top_two, metric_col, is_cat, title, plot_type))\n",
        "            else:\n",
        "                print(f\"Warning: Insufficient unique values for {group_col[0]} in {title}, skipping.\")\n",
        "    except KeyError as e:\n",
        "        print(f\"Warning: Column {group_col[0]} ({str(e)}) not found in df, skipping {title}.\")\n",
        "\n",
        "# Documentation\n",
        "# - hypotheses: List of tuples defining A/B groups for each test, with dynamic selection of top 2 categories for multi-class features.\n",
        "# - group_col: List of column name(s) or specific groups [A, B] for segmentation.\n",
        "# - metric_col: Column or Series for the metric (TotalClaims or Margin).\n",
        "# - is_cat: Boolean for categorical test (chi-squared) vs. numerical (t-test/ANOVA).\n",
        "# - title: Descriptive title for reporting.\n",
        "# - plot_type: Visualization type (box or heatmap).\n",
        "# - Note: A/B pairs are selected as top 2 values by frequency or predefined; skips missing columns or insufficient unique values with warnings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing hypothesis 1/28: Claim Severity by Province\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\2035437510.py:25: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_temp[attr]) or df_temp[attr].nunique() <= 10:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: TotalPremium differs significantly between Gauteng and Western Cape (p = 0.0000), proceed with caution.\n",
            "Warning: VehicleType differs significantly between Gauteng and Western Cape (p = 0.0000), proceed with caution.\n",
            "Claim Severity by Province - P-value: 0.01117179468533579\n",
            "Processing hypothesis 2/28: Claim Severity by Zip Code\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\2035437510.py:25: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_temp[attr]) or df_temp[attr].nunique() <= 10:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: TotalPremium differs significantly between 2000 and 122 (p = 0.0000), proceed with caution.\n",
            "Warning: VehicleType differs significantly between 2000 and 122 (p = 0.0000), proceed with caution.\n",
            "Claim Severity by Zip Code - P-value: 0.393492808828808\n",
            "Processing hypothesis 3/28: Claim Frequency by Gender\n",
            "Warning: VehicleType differs significantly between Male and Female (p = 0.0000), proceed with caution.\n",
            "Claim Frequency by Gender - P-value: 1.0\n",
            "Processing hypothesis 4/28: Margin by Zip Code\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\2035437510.py:25: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_temp[attr]) or df_temp[attr].nunique() <= 10:\n",
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\2035437510.py:25: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_temp[attr]) or df_temp[attr].nunique() <= 10:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: TotalPremium differs significantly between 2000 and 122 (p = 0.0000), proceed with caution.\n",
            "Warning: VehicleType differs significantly between 2000 and 122 (p = 0.0000), proceed with caution.\n",
            "Margin by Zip Code - P-value: 0.12438439377801137\n",
            "Processing hypothesis 5/28: Claim Frequency by Cover ID\n",
            "Warning: TotalPremium differs significantly between 2449 and 2439 (p = 0.0000), proceed with caution.\n",
            "Claim Frequency by Cover ID - P-value: 1.0\n",
            "Processing hypothesis 6/28: Claim Severity by Policy ID\n",
            "Warning: TotalPremium differs significantly between 3870 and 698 (p = 0.0000), proceed with caution.\n",
            "Warning: VehicleType differs significantly between 3870 and 698 (p = 0.0000), proceed with caution.\n",
            "Claim Severity by Policy ID - P-value: 0.6046971837110935\n",
            "Processing hypothesis 7/28: Claim Frequency by VAT Status\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\2035437510.py:25: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_temp[attr]) or df_temp[attr].nunique() <= 10:\n",
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\2035437510.py:25: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_temp[attr]) or df_temp[attr].nunique() <= 10:\n",
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\2035437510.py:25: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_temp[attr]) or df_temp[attr].nunique() <= 10:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: TotalPremium differs significantly between False and True (p = 0.0000), proceed with caution.\n",
            "Warning: VehicleType differs significantly between False and True (p = 0.0000), proceed with caution.\n",
            "Claim Frequency by VAT Status - P-value: 0.6772460288325433\n",
            "Processing hypothesis 8/28: Claim Severity by Citizenship\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\2035437510.py:25: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_temp[attr]) or df_temp[attr].nunique() <= 10:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: TotalPremium differs significantly between    and ZA (p = 0.0000), proceed with caution.\n",
            "Warning: VehicleType differs significantly between    and ZA (p = 0.0000), proceed with caution.\n",
            "Claim Severity by Citizenship - P-value: 0.14310301591693403\n",
            "Processing hypothesis 9/28: Claim Frequency by Legal Type\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\2035437510.py:25: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_temp[attr]) or df_temp[attr].nunique() <= 10:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: TotalPremium differs significantly between Individual and Private company (p = 0.0000), proceed with caution.\n",
            "Warning: VehicleType differs significantly between Individual and Private company (p = 0.0000), proceed with caution.\n",
            "Claim Frequency by Legal Type - P-value: 0.32190811360069893\n",
            "Processing hypothesis 10/28: Margin by Marital Status\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\2035437510.py:25: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_temp[attr]) or df_temp[attr].nunique() <= 10:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: TotalPremium differs significantly between Not specified and Single (p = 0.0000), proceed with caution.\n",
            "Warning: VehicleType differs significantly between Not specified and Single (p = 0.0000), proceed with caution.\n",
            "Margin by Marital Status - P-value: 0.6425579731522808\n",
            "Processing hypothesis 11/28: Claim Severity by Bank\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\2035437510.py:25: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_temp[attr]) or df_temp[attr].nunique() <= 10:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: TotalPremium differs significantly between First National Bank and ABSA Bank (p = 0.0000), proceed with caution.\n",
            "Warning: VehicleType differs significantly between First National Bank and ABSA Bank (p = 0.0000), proceed with caution.\n",
            "Claim Severity by Bank - P-value: 0.35012265932753406\n",
            "Processing hypothesis 12/28: Claim Severity by Main Cresta Zone\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\2035437510.py:25: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_temp[attr]) or df_temp[attr].nunique() <= 10:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: TotalPremium differs significantly between Transvaal (all except Pretoria) and Johannesburg (p = 0.0000), proceed with caution.\n",
            "Warning: VehicleType differs significantly between Transvaal (all except Pretoria) and Johannesburg (p = 0.0000), proceed with caution.\n",
            "Claim Severity by Main Cresta Zone - P-value: 1.722470110839296e-06\n",
            "Processing hypothesis 13/28: Claim Frequency by Sub Cresta Zone\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\2035437510.py:25: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_temp[attr]) or df_temp[attr].nunique() <= 10:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: TotalPremium differs significantly between Johannesburg and Cape Town (p = 0.0000), proceed with caution.\n",
            "Warning: VehicleType differs significantly between Johannesburg and Cape Town (p = 0.0000), proceed with caution.\n",
            "Claim Frequency by Sub Cresta Zone - P-value: 2.7242719626036405e-09\n",
            "Processing hypothesis 14/28: Claim Severity by Vehicle Type\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\2035437510.py:25: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_temp[attr]) or df_temp[attr].nunique() <= 10:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: TotalPremium differs significantly between Passenger Vehicle and Medium Commercial (p = 0.0000), proceed with caution.\n",
            "Warning: VehicleType differs significantly between Passenger Vehicle and Medium Commercial (p = 0.0000), proceed with caution.\n",
            "Claim Severity by Vehicle Type - P-value: 0.09698525652720823\n",
            "Processing hypothesis 15/28: Claim Frequency by Alarm\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\2035437510.py:25: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_temp[attr]) or df_temp[attr].nunique() <= 10:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: VehicleType differs significantly between Yes and No (p = 0.0000), proceed with caution.\n",
            "Claim Frequency by Alarm - P-value: 0.800549295645663\n",
            "Processing hypothesis 16/28: Claim Severity by Make\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\2035437510.py:25: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_temp[attr]) or df_temp[attr].nunique() <= 10:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: TotalPremium differs significantly between TOYOTA and MERCEDES-BENZ (p = 0.0000), proceed with caution.\n",
            "Warning: VehicleType differs significantly between TOYOTA and MERCEDES-BENZ (p = 0.0000), proceed with caution.\n",
            "Claim Severity by Make - P-value: 0.37288823663717263\n",
            "Processing hypothesis 17/28: Claim Frequency by Body Type\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\2035437510.py:25: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_temp[attr]) or df_temp[attr].nunique() <= 10:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: TotalPremium differs significantly between B/S and P/V (p = 0.0000), proceed with caution.\n",
            "Warning: VehicleType differs significantly between B/S and P/V (p = 0.0000), proceed with caution.\n",
            "Claim Frequency by Body Type - P-value: 0.27684044794304713\n",
            "Processing hypothesis 18/28: Margin by Registration Year\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\2035437510.py:25: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_temp[attr]) or df_temp[attr].nunique() <= 10:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: TotalPremium differs significantly between 2014 and 2012 (p = 0.0000), proceed with caution.\n",
            "Warning: VehicleType differs significantly between 2014 and 2012 (p = 0.0000), proceed with caution.\n",
            "Margin by Registration Year - P-value: 0.9495999495916524\n",
            "Processing hypothesis 19/28: Claim Frequency by Term Frequency\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\2035437510.py:25: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_temp[attr]) or df_temp[attr].nunique() <= 10:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: TotalPremium differs significantly between Monthly and Annual (p = 0.0000), proceed with caution.\n",
            "Claim Frequency by Term Frequency - P-value: 1.0\n",
            "Processing hypothesis 20/28: Claim Severity by Cover Category\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\2035437510.py:25: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_temp[attr]) or df_temp[attr].nunique() <= 10:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: TotalPremium differs significantly between Passenger Liability and Third Party (p = 0.0000), proceed with caution.\n",
            "Claim Severity by Cover Category - P-value: 0.0007963006407114917\n",
            "Processing hypothesis 21/28: Claim Frequency by Product\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\2035437510.py:25: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_temp[attr]) or df_temp[attr].nunique() <= 10:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: TotalPremium differs significantly between Mobility Commercial Cover: Monthly and Mobility Metered Taxis: Monthly (p = 0.0000), proceed with caution.\n",
            "Warning: VehicleType differs significantly between Mobility Commercial Cover: Monthly and Mobility Metered Taxis: Monthly (p = 0.0000), proceed with caution.\n",
            "Claim Frequency by Product - P-value: 0.9059690663251299\n",
            "Processing hypothesis 22/28: Claim Frequency by Premium Level\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\2035437510.py:25: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_temp[attr]) or df_temp[attr].nunique() <= 10:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: TotalPremium differs significantly between Low and Medium-High (p = 0.0000), proceed with caution.\n",
            "Warning: VehicleType differs significantly between Low and Medium-High (p = 0.0000), proceed with caution.\n",
            "Claim Frequency by Premium Level - P-value: 1.0085945781954506e-136\n",
            "Processing hypothesis 23/28: Claim Severity by Sum Insured\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\2035437510.py:25: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_temp[attr]) or df_temp[attr].nunique() <= 10:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: TotalPremium differs significantly between Medium-Low and Low (p = 0.0000), proceed with caution.\n",
            "Warning: VehicleType differs significantly between Medium-Low and Low (p = 0.0236), proceed with caution.\n",
            "Claim Severity by Sum Insured - P-value: 1.5856815917884146e-19\n",
            "Processing hypothesis 24/28: Claim Severity by Month\n",
            "Claim Severity by Month - P-value: 0.021006181796829802\n",
            "Total execution time: 35.99 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\2035437510.py:25: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(df_temp[attr]) or df_temp[attr].nunique() <= 10:\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Execute Hypothesis Tests with Equivalence Checks\n",
        "# Initialize results dictionary\n",
        "results = {}\n",
        "\n",
        "# Add time tracking\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "# Loop through each hypothesis and perform tests\n",
        "for i, (group_col, [group_a, group_b], metric_col, is_cat, title, plot_type) in enumerate(hypotheses):\n",
        "    print(f\"Processing hypothesis {i+1}/28: {title}\")\n",
        "    # Filter data to A/B groups\n",
        "    df_temp = df[df[group_col[0]].isin([group_a, group_b])].copy()\n",
        "    if df_temp.empty or df_temp[group_col[0]].nunique() < 2:\n",
        "        print(f\"Warning: Insufficient data for {title}, skipping.\")\n",
        "        continue\n",
        "    \n",
        "    # Equivalence checks on key attributes\n",
        "    attributes_to_check = [\"TotalPremium\", \"VehicleType\"]  # Example attributes\n",
        "    for attr in attributes_to_check:\n",
        "        if attr in df_temp.columns:\n",
        "            group_a_data = df_temp[df_temp[group_col[0]] == group_a][attr].dropna()\n",
        "            group_b_data = df_temp[df_temp[group_col[0]] == group_b][attr].dropna()\n",
        "            if len(group_a_data) > 0 and len(group_b_data) > 0:\n",
        "                if pd.api.types.is_categorical_dtype(df_temp[attr]) or df_temp[attr].nunique() <= 10:\n",
        "                    contingency = pd.crosstab(df_temp[group_col[0]], df_temp[attr])\n",
        "                    if contingency.shape[1] > 1:  # Ensure valid contingency table\n",
        "                        chi2, p_eq, dof, _ = stats.chi2_contingency(contingency)\n",
        "                    else:\n",
        "                        chi2, p_eq, dof, _ = (0, 1, 0, None)  # Fallback 4-tuple\n",
        "                else:\n",
        "                    t_stat, p_eq = stats.ttest_ind(group_a_data, group_b_data, equal_var=False) if len(group_a_data) > 1 and len(group_b_data) > 1 else (0, 1)\n",
        "                if p_eq < 0.05:\n",
        "                    print(f\"Warning: {attr} differs significantly between {group_a} and {group_b} (p = {p_eq:.4f}), proceed with caution.\")\n",
        "    \n",
        "    # Perform hypothesis test\n",
        "    if plot_type == \"heatmap\":\n",
        "        df_temp = df_temp[df_temp[\"TotalClaims\"] > 0].copy()\n",
        "    result, df_temp = test_hypothesis(df_temp, group_col[0], metric_col, is_cat)\n",
        "    results[group_col[0] + \"_\" + str(metric_col) if not isinstance(metric_col, pd.Series) else group_col[0] + \"_temp_metric\"] = result\n",
        "    if result:\n",
        "        p_value = result.get(\"p_value\", \"N/A\")\n",
        "        print(f\"{title} - P-value: {p_value}\")\n",
        "\n",
        "# End time tracking\n",
        "print(f\"Total execution time: {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "# Documentation\n",
        "# - results: Stores test outcomes with A/B-specific results.\n",
        "# - test_hypothesis: Applies statistical tests after filtering to A/B groups.\n",
        "# - Equivalence Checks: Tests TotalPremium (numerical) and VehicleType (categorical) for similarity; warns if p < 0.05.\n",
        "# - Note: Handles invalid contingency tables with a 4-tuple fallback; skips tests with insufficient data; adjust attributes_to_check based on dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating visualization 1/28: Claim Severity by Province\n",
            "Original unique values in Province for Claim Severity by Province: 9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\4046931547.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_temp = df_filtered.groupby(group_col[0], group_keys=False, observed=True).apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled unique values in Province for Claim Severity by Province: 2\n",
            "Generating visualization 2/28: Claim Severity by Zip Code\n",
            "Original unique values in PostalCode for Claim Severity by Zip Code: 780\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\4046931547.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_temp = df_filtered.groupby(group_col[0], group_keys=False, observed=True).apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled unique values in PostalCode for Claim Severity by Zip Code: 2\n",
            "Generating visualization 3/28: Claim Frequency by Gender\n",
            "Original unique values in Gender for Claim Frequency by Gender: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\4046931547.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_temp = df_filtered.groupby(group_col[0], group_keys=False, observed=True).apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled unique values in Gender for Claim Frequency by Gender: 2\n",
            "Generating visualization 4/28: Margin by Zip Code\n",
            "Original unique values in PostalCode for Margin by Zip Code: 780\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\4046931547.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_temp = df_filtered.groupby(group_col[0], group_keys=False, observed=True).apply(\n",
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\4046931547.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_temp = df_filtered.groupby(group_col[0], group_keys=False, observed=True).apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled unique values in PostalCode for Margin by Zip Code: 2\n",
            "Generating visualization 5/28: Claim Frequency by Cover ID\n",
            "Original unique values in UnderwrittenCoverID for Claim Frequency by Cover ID: 98265\n",
            "Sampled unique values in UnderwrittenCoverID for Claim Frequency by Cover ID: 2\n",
            "Generating visualization 6/28: Claim Severity by Policy ID\n",
            "Original unique values in PolicyID for Claim Severity by Policy ID: 5113\n",
            "Sampled unique values in PolicyID for Claim Severity by Policy ID: 2\n",
            "Generating visualization 7/28: Claim Frequency by VAT Status\n",
            "Original unique values in IsVATRegistered for Claim Frequency by VAT Status: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\4046931547.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_temp = df_filtered.groupby(group_col[0], group_keys=False, observed=True).apply(\n",
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\4046931547.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_temp = df_filtered.groupby(group_col[0], group_keys=False, observed=True).apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled unique values in IsVATRegistered for Claim Frequency by VAT Status: 2\n",
            "Generating visualization 8/28: Claim Severity by Citizenship\n",
            "Original unique values in Citizenship for Claim Severity by Citizenship: 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\4046931547.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_temp = df_filtered.groupby(group_col[0], group_keys=False, observed=True).apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled unique values in Citizenship for Claim Severity by Citizenship: 2\n",
            "Generating visualization 9/28: Claim Frequency by Legal Type\n",
            "Original unique values in LegalType for Claim Frequency by Legal Type: 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\4046931547.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_temp = df_filtered.groupby(group_col[0], group_keys=False, observed=True).apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled unique values in LegalType for Claim Frequency by Legal Type: 2\n",
            "Generating visualization 10/28: Margin by Marital Status\n",
            "Original unique values in MaritalStatus for Margin by Marital Status: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\4046931547.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_temp = df_filtered.groupby(group_col[0], group_keys=False, observed=True).apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled unique values in MaritalStatus for Margin by Marital Status: 2\n",
            "Generating visualization 11/28: Claim Severity by Bank\n",
            "Original unique values in Bank for Claim Severity by Bank: 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\4046931547.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_temp = df_filtered.groupby(group_col[0], group_keys=False, observed=True).apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled unique values in Bank for Claim Severity by Bank: 2\n",
            "Generating visualization 12/28: Claim Severity by Main Cresta Zone\n",
            "Original unique values in MainCrestaZone for Claim Severity by Main Cresta Zone: 16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\4046931547.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_temp = df_filtered.groupby(group_col[0], group_keys=False, observed=True).apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled unique values in MainCrestaZone for Claim Severity by Main Cresta Zone: 2\n",
            "Generating visualization 13/28: Claim Frequency by Sub Cresta Zone\n",
            "Original unique values in SubCrestaZone for Claim Frequency by Sub Cresta Zone: 44\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\4046931547.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_temp = df_filtered.groupby(group_col[0], group_keys=False, observed=True).apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled unique values in SubCrestaZone for Claim Frequency by Sub Cresta Zone: 2\n",
            "Generating visualization 14/28: Claim Severity by Vehicle Type\n",
            "Original unique values in VehicleType for Claim Severity by Vehicle Type: 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\4046931547.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_temp = df_filtered.groupby(group_col[0], group_keys=False, observed=True).apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled unique values in VehicleType for Claim Severity by Vehicle Type: 2\n",
            "Generating visualization 15/28: Claim Frequency by Alarm\n",
            "Original unique values in AlarmImmobiliser for Claim Frequency by Alarm: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\4046931547.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_temp = df_filtered.groupby(group_col[0], group_keys=False, observed=True).apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled unique values in AlarmImmobiliser for Claim Frequency by Alarm: 2\n",
            "Generating visualization 16/28: Claim Severity by Make\n",
            "Original unique values in make for Claim Severity by Make: 43\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\4046931547.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_temp = df_filtered.groupby(group_col[0], group_keys=False, observed=True).apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled unique values in make for Claim Severity by Make: 2\n",
            "Generating visualization 17/28: Claim Frequency by Body Type\n",
            "Original unique values in bodytype for Claim Frequency by Body Type: 13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\4046931547.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_temp = df_filtered.groupby(group_col[0], group_keys=False, observed=True).apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled unique values in bodytype for Claim Frequency by Body Type: 2\n",
            "Generating visualization 18/28: Margin by Registration Year\n",
            "Original unique values in RegistrationYear for Margin by Registration Year: 22\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\4046931547.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_temp = df_filtered.groupby(group_col[0], group_keys=False, observed=True).apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled unique values in RegistrationYear for Margin by Registration Year: 2\n",
            "Generating visualization 19/28: Claim Frequency by Term Frequency\n",
            "Original unique values in TermFrequency for Claim Frequency by Term Frequency: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\4046931547.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_temp = df_filtered.groupby(group_col[0], group_keys=False, observed=True).apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled unique values in TermFrequency for Claim Frequency by Term Frequency: 2\n",
            "Generating visualization 20/28: Claim Severity by Cover Category\n",
            "Original unique values in CoverCategory for Claim Severity by Cover Category: 28\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\4046931547.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_temp = df_filtered.groupby(group_col[0], group_keys=False, observed=True).apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled unique values in CoverCategory for Claim Severity by Cover Category: 2\n",
            "Generating visualization 21/28: Claim Frequency by Product\n",
            "Original unique values in Product for Claim Frequency by Product: 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\4046931547.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_temp = df_filtered.groupby(group_col[0], group_keys=False, observed=True).apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled unique values in Product for Claim Frequency by Product: 2\n",
            "Generating visualization 22/28: Claim Frequency by Premium Level\n",
            "Original unique values in TotalPremiumBin for Claim Frequency by Premium Level: 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\4046931547.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_temp = df_filtered.groupby(group_col[0], group_keys=False, observed=True).apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled unique values in TotalPremiumBin for Claim Frequency by Premium Level: 2\n",
            "Generating visualization 23/28: Claim Severity by Sum Insured\n",
            "Original unique values in SumInsuredBin for Claim Severity by Sum Insured: 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\4046931547.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_temp = df_filtered.groupby(group_col[0], group_keys=False, observed=True).apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled unique values in SumInsuredBin for Claim Severity by Sum Insured: 2\n",
            "Generating visualization 24/28: Claim Severity by Month\n",
            "Original unique values in TransactionMonth for Claim Severity by Month: 23\n",
            "Sampled unique values in TransactionMonth for Claim Severity by Month: 2\n",
            "Total visualization time: 24.14 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22132\\4046931547.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_temp = df_filtered.groupby(group_col[0], group_keys=False, observed=True).apply(\n"
          ]
        }
      ],
      "source": [
        "# Cell 6: Generate Visualizations\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "# Loop through each hypothesis and generate visualizations\n",
        "for i, (group_col, [group_a, group_b], metric_col, is_cat, title, plot_type) in enumerate(hypotheses):\n",
        "    print(f\"Generating visualization {i+1}/28: {title}\")\n",
        "    print(f\"Original unique values in {group_col[0]} for {title}: {df[group_col[0]].nunique()}\")\n",
        "    # Filter data to A/B groups and check existence\n",
        "    df_filtered = df[df[group_col[0]].isin([group_a, group_b])].copy()\n",
        "    if df_filtered.empty or df_filtered[group_col[0]].nunique() < 2:\n",
        "        print(f\"Warning: Insufficient data for {group_a} and {group_b} in {title}, skipping.\")\n",
        "        continue\n",
        "    if plot_type == \"heatmap\":\n",
        "        df_filtered = df_filtered[df_filtered[\"TotalClaims\"] > 0].copy()\n",
        "    # Stratified sampling to ensure both A/B groups\n",
        "    sample_size = min(5000, len(df_filtered))\n",
        "    if sample_size > 0:\n",
        "        df_temp = df_filtered.groupby(group_col[0], group_keys=False, observed=True).apply(\n",
        "            lambda x: x.sample(min(len(x), sample_size//2), random_state=42)\n",
        "        ).reset_index(drop=True)\n",
        "        print(f\"Sampled unique values in {group_col[0]} for {title}: {df_temp[group_col[0]].nunique()}\")\n",
        "    else:\n",
        "        print(f\"Warning: No data to sample for {group_a} and {group_b} in {title}, skipping.\")\n",
        "        continue\n",
        "    # Limit to top 50 groups if more than 50 unique values (though A/B limits this)\n",
        "    if df_temp[group_col[0]].nunique() > 50:\n",
        "        print(f\"Reducing {group_col[0]} to top 50 groups\")\n",
        "        top_groups = df_temp[group_col[0]].value_counts().head(50).index\n",
        "        df_temp = df_temp[df_temp[group_col[0]].isin(top_groups)]\n",
        "    result = results.get(group_col[0] + \"_\" + str(metric_col) if not isinstance(metric_col, pd.Series) else group_col[0] + \"_temp_metric\", None)\n",
        "    if result:\n",
        "        # Modify test_hypothesis to skip Tukey for many groups\n",
        "        def modified_test_hypothesis(df, group_col, metric_col, is_cat):\n",
        "            temp_col = None\n",
        "            if isinstance(metric_col, pd.Series):\n",
        "                temp_col = \"temp_metric\"\n",
        "                df = df.copy()\n",
        "                df[temp_col] = metric_col\n",
        "                metric_col = temp_col\n",
        "            if is_cat:\n",
        "                contingency = pd.crosstab(df[group_col], df['TotalClaims'] > 0)\n",
        "                chi2, p, dof, expected = stats.chi2_contingency(contingency)\n",
        "                return {'statistic': chi2, 'p_value': p, 'dof': dof}, df\n",
        "            else:\n",
        "                groups = [group[metric_col].dropna() for name, group in df.groupby(group_col, observed=True) if not group[metric_col].dropna().empty]\n",
        "                if len(groups) == 2:\n",
        "                    t_stat, p_value = stats.ttest_ind(groups[0], groups[1])\n",
        "                    return {'statistic': t_stat, 'p_value': p_value}, df\n",
        "                elif len(groups) > 2 and len(groups) <= 50:  # Only run ANOVA/Tukey if groups <= 50\n",
        "                    anova = stats.f_oneway(*groups)\n",
        "                    tukey = pairwise_tukeyhsd(df[metric_col].dropna(), df[group_col].dropna())\n",
        "                    return {'anova_statistic': anova.statistic, 'p_value': anova.pvalue, 'tukey_results': tukey}, df\n",
        "                else:\n",
        "                    anova = stats.f_oneway(*groups) if groups else (0, 1)  # Fallback ANOVA without Tukey\n",
        "                    return {'anova_statistic': anova[0], 'p_value': anova[1]}, df\n",
        "        result, df_temp = modified_test_hypothesis(df_temp, group_col[0], metric_col, is_cat)\n",
        "        visualize_results(df_temp, group_col[0], metric_col, title, plot_type if plot_type else \"box\")\n",
        "\n",
        "print(f\"Total visualization time: {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "# Documentation\n",
        "# - visualize_results: Generates plots based on test outcomes.\n",
        "# - Note: Uses stratified sampling (up to 5,000 rows) with observed=True to ensure A/B groups, limits groups to 50; skips Tukey HSD for >50 groups.\n",
        "# - Adjustment: Filters to A/B groups and skips if data is insufficient; suppresses FutureWarnings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Significant Results (p <= 0.05):\n",
            "Province_TotalClaims - P-value: 0.01117179468533579\n",
            "MainCrestaZone_TotalClaims - P-value: 1.722470110839296e-06\n",
            "SubCrestaZone_TotalClaims - P-value: 2.7242719626036405e-09\n",
            "CoverCategory_TotalClaims - P-value: 0.0007963006407114917\n",
            "TotalPremiumBin_TotalClaims - P-value: 1.0085945781954506e-136\n",
            "SumInsuredBin_TotalClaims - P-value: 1.5856815917884146e-19\n",
            "TransactionMonth_TotalClaims - P-value: 0.021006181796829802\n"
          ]
        }
      ],
      "source": [
        "# Cell 7: Summarize Significant Results\n",
        "# Filter and display significant hypotheses (p <= 0.05)\n",
        "significant_results = {k: v for k, v in results.items() if v and v.get(\"p_value\", 1) <= 0.05}\n",
        "print(\"Significant Results (p <= 0.05):\")\n",
        "for hypo, result in significant_results.items():\n",
        "    print(\"{0} - P-value: {1}\".format(hypo, result[\"p_value\"]))\n",
        "\n",
        "# Documentation\n",
        "# - significant_results: Highlights hypotheses with p <= 0.05.\n",
        "# - print: Lists significant findings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Hypothesis Testing Results and Interpretations\n",
            "- Province_TotalClaims: P-value = 0.01117179468533579, Decision: Reject H (Significant)\n",
            "  - Statistic: 2.5372883209254207\n",
            "  - Interpretation: Significant difference in claim frequency between provinces (e.g., Gauteng vs. Western Cape), likely due to urban density or risk exposure.\n",
            "  - Recommendation: Consider a 5-10% premium adjustment for high-claim provinces after A/B validation.\n",
            "  - Note: Validate with larger dataset or additional A/B tests.\n",
            "\n",
            "- PostalCode_TotalClaims: P-value = 0.393492808828808, Decision: Fail to Reject H (Not Significant)\n",
            "  - Interpretation: No significant difference detected; current pricing or policies may be appropriate.\n",
            "  - Recommendation: Maintain current strategy, but monitor for future trends.\n",
            "  - Note: Validate with larger dataset or additional A/B tests.\n",
            "\n",
            "- Gender_TotalClaims: P-value = 1.0, Decision: Fail to Reject H (Not Significant)\n",
            "  - Interpretation: No significant difference detected; current pricing or policies may be appropriate.\n",
            "  - Recommendation: Maintain current strategy, but monitor for future trends.\n",
            "  - Note: Validate with larger dataset or additional A/B tests.\n",
            "\n",
            "- PostalCode_temp_metric: P-value = 0.12438439377801137, Decision: Fail to Reject H (Not Significant)\n",
            "  - Interpretation: No significant difference detected; current pricing or policies may be appropriate.\n",
            "  - Recommendation: Maintain current strategy, but monitor for future trends.\n",
            "  - Note: Validate with larger dataset or additional A/B tests.\n",
            "\n",
            "- UnderwrittenCoverID_TotalClaims: P-value = 1.0, Decision: Fail to Reject H (Not Significant)\n",
            "  - Interpretation: No significant difference detected; current pricing or policies may be appropriate.\n",
            "  - Recommendation: Maintain current strategy, but monitor for future trends.\n",
            "  - Note: Validate with larger dataset or additional A/B tests.\n",
            "\n",
            "- PolicyID_TotalClaims: P-value = 0.6046971837110935, Decision: Fail to Reject H (Not Significant)\n",
            "  - Interpretation: No significant difference detected; current pricing or policies may be appropriate.\n",
            "  - Recommendation: Maintain current strategy, but monitor for future trends.\n",
            "  - Note: Validate with larger dataset or additional A/B tests.\n",
            "\n",
            "- IsVATRegistered_TotalClaims: P-value = 0.6772460288325433, Decision: Fail to Reject H (Not Significant)\n",
            "  - Interpretation: No significant difference detected; current pricing or policies may be appropriate.\n",
            "  - Recommendation: Maintain current strategy, but monitor for future trends.\n",
            "  - Note: Validate with larger dataset or additional A/B tests.\n",
            "\n",
            "- Citizenship_TotalClaims: P-value = 0.14310301591693403, Decision: Fail to Reject H (Not Significant)\n",
            "  - Interpretation: No significant difference detected; current pricing or policies may be appropriate.\n",
            "  - Recommendation: Maintain current strategy, but monitor for future trends.\n",
            "  - Note: Validate with larger dataset or additional A/B tests.\n",
            "\n",
            "- LegalType_TotalClaims: P-value = 0.32190811360069893, Decision: Fail to Reject H (Not Significant)\n",
            "  - Interpretation: No significant difference detected; current pricing or policies may be appropriate.\n",
            "  - Recommendation: Maintain current strategy, but monitor for future trends.\n",
            "  - Note: Validate with larger dataset or additional A/B tests.\n",
            "\n",
            "- MaritalStatus_temp_metric: P-value = 0.6425579731522808, Decision: Fail to Reject H (Not Significant)\n",
            "  - Interpretation: No significant difference detected; current pricing or policies may be appropriate.\n",
            "  - Recommendation: Maintain current strategy, but monitor for future trends.\n",
            "  - Note: Validate with larger dataset or additional A/B tests.\n",
            "\n",
            "- Bank_TotalClaims: P-value = 0.35012265932753406, Decision: Fail to Reject H (Not Significant)\n",
            "  - Interpretation: No significant difference detected; current pricing or policies may be appropriate.\n",
            "  - Recommendation: Maintain current strategy, but monitor for future trends.\n",
            "  - Note: Validate with larger dataset or additional A/B tests.\n",
            "\n",
            "- MainCrestaZone_TotalClaims: P-value = 1.722470110839296e-06, Decision: Reject H (Significant)\n",
            "  - Statistic: 4.78359636279972\n",
            "  - Interpretation: Zone-based differences in claims suggest geographic risk variations.\n",
            "  - Recommendation: Adjust underwriting guidelines by zone, targeting 10-15% premium increases in high-risk areas.\n",
            "  - Note: Validate with larger dataset or additional A/B tests.\n",
            "\n",
            "- SubCrestaZone_TotalClaims: P-value = 2.7242719626036405e-09, Decision: Reject H (Significant)\n",
            "  - Statistic: 35.37162324943985\n",
            "  - Interpretation: Zone-based differences in claims suggest geographic risk variations.\n",
            "  - Recommendation: Adjust underwriting guidelines by zone, targeting 10-15% premium increases in high-risk areas.\n",
            "  - Note: Validate with larger dataset or additional A/B tests.\n",
            "\n",
            "- VehicleType_TotalClaims: P-value = 0.09698525652720823, Decision: Fail to Reject H (Not Significant)\n",
            "  - Interpretation: No significant difference detected; current pricing or policies may be appropriate.\n",
            "  - Recommendation: Maintain current strategy, but monitor for future trends.\n",
            "  - Note: Validate with larger dataset or additional A/B tests.\n",
            "\n",
            "- AlarmImmobiliser_TotalClaims: P-value = 0.800549295645663, Decision: Fail to Reject H (Not Significant)\n",
            "  - Interpretation: No significant difference detected; current pricing or policies may be appropriate.\n",
            "  - Recommendation: Maintain current strategy, but monitor for future trends.\n",
            "  - Note: Validate with larger dataset or additional A/B tests.\n",
            "\n",
            "- make_TotalClaims: P-value = 0.37288823663717263, Decision: Fail to Reject H (Not Significant)\n",
            "  - Interpretation: No significant difference detected; current pricing or policies may be appropriate.\n",
            "  - Recommendation: Maintain current strategy, but monitor for future trends.\n",
            "  - Note: Validate with larger dataset or additional A/B tests.\n",
            "\n",
            "- bodytype_TotalClaims: P-value = 0.27684044794304713, Decision: Fail to Reject H (Not Significant)\n",
            "  - Interpretation: No significant difference detected; current pricing or policies may be appropriate.\n",
            "  - Recommendation: Maintain current strategy, but monitor for future trends.\n",
            "  - Note: Validate with larger dataset or additional A/B tests.\n",
            "\n",
            "- RegistrationYear_temp_metric: P-value = 0.9495999495916524, Decision: Fail to Reject H (Not Significant)\n",
            "  - Interpretation: No significant difference detected; current pricing or policies may be appropriate.\n",
            "  - Recommendation: Maintain current strategy, but monitor for future trends.\n",
            "  - Note: Validate with larger dataset or additional A/B tests.\n",
            "\n",
            "- TermFrequency_TotalClaims: P-value = 1.0, Decision: Fail to Reject H (Not Significant)\n",
            "  - Interpretation: No significant difference detected; current pricing or policies may be appropriate.\n",
            "  - Recommendation: Maintain current strategy, but monitor for future trends.\n",
            "  - Note: Validate with larger dataset or additional A/B tests.\n",
            "\n",
            "- CoverCategory_TotalClaims: P-value = 0.0007963006407114917, Decision: Reject H (Significant)\n",
            "  - Statistic: -3.3541354509564183\n",
            "  - Interpretation: Certain cover categories drive higher claims, possibly due to policy type or usage.\n",
            "  - Recommendation: Review cover category pricing, potentially increasing by 5-10% for high-claim categories.\n",
            "  - Note: Validate with larger dataset or additional A/B tests.\n",
            "\n",
            "- Product_TotalClaims: P-value = 0.9059690663251299, Decision: Fail to Reject H (Not Significant)\n",
            "  - Interpretation: No significant difference detected; current pricing or policies may be appropriate.\n",
            "  - Recommendation: Maintain current strategy, but monitor for future trends.\n",
            "  - Note: Validate with larger dataset or additional A/B tests.\n",
            "\n",
            "- TotalPremiumBin_TotalClaims: P-value = 1.0085945781954506e-136, Decision: Reject H (Significant)\n",
            "  - Statistic: 619.4024756260602\n",
            "  - Interpretation: Claim frequency varies significantly with premium or insured value bins, indicating risk tiering.\n",
            "  - Recommendation: Implement tiered pricing with 10-20% increases for higher bins after further analysis.\n",
            "  - Note: Validate with larger dataset or additional A/B tests.\n",
            "\n",
            "- SumInsuredBin_TotalClaims: P-value = 1.5856815917884146e-19, Decision: Reject H (Significant)\n",
            "  - Statistic: -9.039024720089774\n",
            "  - Interpretation: Claim frequency varies significantly with premium or insured value bins, indicating risk tiering.\n",
            "  - Recommendation: Implement tiered pricing with 10-20% increases for higher bins after further analysis.\n",
            "  - Note: Validate with larger dataset or additional A/B tests.\n",
            "\n",
            "- TransactionMonth_TotalClaims: P-value = 0.021006181796829802, Decision: Reject H (Significant)\n",
            "  - Statistic: -2.322216185132755\n",
            "  - Interpretation: Seasonal claim patterns suggest time-based risk factors.\n",
            "  - Recommendation: Adjust reserves or premiums by 5-10% for high-claim months (e.g., year-end).\n",
            "  - Note: Validate with larger dataset or additional A/B tests.\n",
            "\n",
            "### General Recommendations\n",
            "- Revisit skipped hypotheses (e.g., PostalCode) with adjusted A/B pairs to achieve 28/28 coverage.\n",
            "- Conduct quarterly reviews to refine models based on new data.\n",
            "- Prioritize A/B validation for significant results before implementing premium changes.\n"
          ]
        }
      ],
      "source": [
        "# Cell 8: Detailed Interpretation and Recommendations\n",
        "print(\"### Hypothesis Testing Results and Interpretations\")\n",
        "for key, result in results.items():\n",
        "    if result and 'p_value' in result:\n",
        "        decision = \"Reject H (Significant)\" if result['p_value'] <= 0.05 else \"Fail to Reject H (Not Significant)\"\n",
        "        print(f\"- {key}: P-value = {result['p_value']}, Decision: {decision}\")\n",
        "        if decision == \"Reject H (Significant)\":\n",
        "            if 'statistic' in result:\n",
        "                print(f\"  - Statistic: {result['statistic']}\")\n",
        "            # Interpretations and Recommendations\n",
        "            if 'Province' in key:\n",
        "                print(\"  - Interpretation: Significant difference in claim frequency between provinces (e.g., Gauteng vs. Western Cape), likely due to urban density or risk exposure.\")\n",
        "                print(\"  - Recommendation: Consider a 5-10% premium adjustment for high-claim provinces after A/B validation.\")\n",
        "            elif 'MainCrestaZone' in key or 'SubCrestaZone' in key:\n",
        "                print(\"  - Interpretation: Zone-based differences in claims suggest geographic risk variations.\")\n",
        "                print(\"  - Recommendation: Adjust underwriting guidelines by zone, targeting 10-15% premium increases in high-risk areas.\")\n",
        "            elif 'CoverCategory' in key:\n",
        "                print(\"  - Interpretation: Certain cover categories drive higher claims, possibly due to policy type or usage.\")\n",
        "                print(\"  - Recommendation: Review cover category pricing, potentially increasing by 5-10% for high-claim categories.\")\n",
        "            elif 'TotalPremiumBin' in key or 'SumInsuredBin' in key:\n",
        "                print(\"  - Interpretation: Claim frequency varies significantly with premium or insured value bins, indicating risk tiering.\")\n",
        "                print(\"  - Recommendation: Implement tiered pricing with 10-20% increases for higher bins after further analysis.\")\n",
        "            elif 'TransactionMonth' in key:\n",
        "                print(\"  - Interpretation: Seasonal claim patterns suggest time-based risk factors.\")\n",
        "                print(\"  - Recommendation: Adjust reserves or premiums by 5-10% for high-claim months (e.g., year-end).\")\n",
        "        else:\n",
        "            print(\"  - Interpretation: No significant difference detected; current pricing or policies may be appropriate.\")\n",
        "            print(\"  - Recommendation: Maintain current strategy, but monitor for future trends.\")\n",
        "        print(\"  - Note: Validate with larger dataset or additional A/B tests.\\n\")\n",
        "\n",
        "print(\"### General Recommendations\")\n",
        "print(\"- Revisit skipped hypotheses (e.g., PostalCode) with adjusted A/B pairs to achieve 28/28 coverage.\")\n",
        "print(\"- Conduct quarterly reviews to refine models based on new data.\")\n",
        "print(\"- Prioritize A/B validation for significant results before implementing premium changes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results exported to task3_results.csv\n",
            "Analysis exported to task3_analysis.md\n"
          ]
        }
      ],
      "source": [
        "# Cell 9: Export Results\n",
        "\n",
        "# Export results to CSV\n",
        "results_df = pd.DataFrame([(k, v.get('p_value', 'N/A'), v.get('statistic', 'N/A'), \n",
        "                           \"Reject H\" if v.get('p_value', 1) <= 0.05 else \"Fail to Reject H\") \n",
        "                          for k, v in results.items()],\n",
        "                         columns=['Hypothesis', 'P-value', 'Statistic', 'Decision'])\n",
        "results_df.to_csv('task3_results.csv', index=False)\n",
        "print(\"Results exported to task3_results.csv\")\n",
        "\n",
        "# Export analysis to MD with UTF-8 encoding\n",
        "with open('task3_analysis.md', 'w', encoding='utf-8') as f:\n",
        "    f.write(\"# Task 3 Analysis Report\\n\")\n",
        "    f.write(\"## Hypothesis Testing Results\\n\")\n",
        "    for key, result in results.items():\n",
        "        if result and 'p_value' in result:\n",
        "            decision = \"Reject H\" if result['p_value'] <= 0.05 else \"Fail to Reject H\"\n",
        "            f.write(f\"- {key}: P-value = {result['p_value']}, Decision: {decision}\\n\")\n",
        "    f.write(\"## Interpretations and Recommendations\\n\")\n",
        "    for key, result in results.items():\n",
        "        if result and 'p_value' in result and result['p_value'] <= 0.05:\n",
        "            f.write(f\"- {key}\\n\")\n",
        "            if 'Province' in key:\n",
        "                f.write(\"  - Interpretation: Significant difference in claim frequency between provinces.\\n\")\n",
        "                f.write(\"  - Recommendation: Consider a 5-10% premium adjustment for high-claim provinces.\\n\")\n",
        "            # Add other conditions as in Cell 8\n",
        "    f.write(\"## Notes\\n- 4 hypotheses skipped (e.g., PostalCode); revisit A/B pairs for full 28/28 coverage.\\n\")\n",
        "print(\"Analysis exported to task3_analysis.md\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
